{"cells":[{"cell_type":"markdown","metadata":{"id":"r-TtR3cJV15M"},"source":["# Day 14. Task 04\n","# Ансамбли"]},{"cell_type":"markdown","metadata":{"id":"QYEurfS4V15V"},"source":["## 0. Импорты"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"CffxuO9ZV15Y","executionInfo":{"status":"ok","timestamp":1668097325863,"user_tz":-180,"elapsed":2299,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}}},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import  LogisticRegression"]},{"cell_type":"markdown","metadata":{"id":"cVdyuZXOV15b"},"source":["## 1. Препроцессинг"]},{"cell_type":"markdown","metadata":{"id":"ZVKFEge2V15c"},"source":["1. Загрузите снова тот же датафрейм, как и в прошлом задании.\n","2. Воспользуйтесь `train_test_split` с параметрами `test_size=0.2`, `random_state=21` и получите `X_train`, `y_train`, `X_test`, `y_test`. Используйте дополнительный параметр `stratify`. А затем из полученных `X_train`, `y_train` сделайте снова сплит на `X_train`, `y_train`, `X_valid`, `y_valid`. Таким образом у вас появятся три датасета: обучающая выборка, валидационная выборка и тестовая выборка."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_rXpnI7WX61","executionInfo":{"status":"ok","timestamp":1668097413272,"user_tz":-180,"elapsed":67204,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"954d52c8-d126-482b-96c4-bbe491a20221"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      numTrials  hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n","0             1     5          4         0.0         0.0          0.0   \n","1             2     5          4         0.0         0.0          0.0   \n","2             3     5          4         0.0         0.0          0.0   \n","3             4     5          4         0.0         0.0          0.0   \n","4             5     5          4         0.0         0.0          0.0   \n","...         ...   ...        ...         ...         ...          ...   \n","1681          9    20          3         0.0         0.0          0.0   \n","1682          6    20          3         0.0         1.0          0.0   \n","1683          7    20          3         0.0         1.0          0.0   \n","1684          8    20          3         0.0         1.0          0.0   \n","1685          9    20          3         0.0         1.0          0.0   \n","\n","      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n","0             0.0          0.0          0.0          0.0  ...            0.0   \n","1             0.0          0.0          0.0          0.0  ...            0.0   \n","2             0.0          0.0          0.0          0.0  ...            0.0   \n","3             0.0          0.0          0.0          0.0  ...            0.0   \n","4             0.0          0.0          0.0          0.0  ...            0.0   \n","...           ...          ...          ...          ...  ...            ...   \n","1681          0.0          0.0          0.0          0.0  ...            0.0   \n","1682          0.0          0.0          0.0          0.0  ...            0.0   \n","1683          0.0          0.0          0.0          0.0  ...            0.0   \n","1684          0.0          0.0          0.0          0.0  ...            0.0   \n","1685          0.0          0.0          0.0          0.0  ...            0.0   \n","\n","      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n","0               0.0             0.0             0.0             0.0   \n","1               0.0             0.0             0.0             0.0   \n","2               0.0             0.0             0.0             0.0   \n","3               0.0             0.0             0.0             0.0   \n","4               0.0             0.0             0.0             0.0   \n","...             ...             ...             ...             ...   \n","1681            0.0             0.0             0.0             0.0   \n","1682            0.0             0.0             0.0             0.0   \n","1683            0.0             0.0             0.0             0.0   \n","1684            0.0             0.0             0.0             0.0   \n","1685            0.0             0.0             0.0             0.0   \n","\n","      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n","0                 0.0             0.0             0.0              0.0   \n","1                 0.0             0.0             0.0              0.0   \n","2                 0.0             0.0             0.0              0.0   \n","3                 0.0             0.0             0.0              0.0   \n","4                 0.0             0.0             0.0              0.0   \n","...               ...             ...             ...              ...   \n","1681              0.0             0.0             0.0              1.0   \n","1682              0.0             0.0             0.0              1.0   \n","1683              0.0             0.0             0.0              1.0   \n","1684              0.0             0.0             0.0              1.0   \n","1685              0.0             0.0             0.0              1.0   \n","\n","      labname_project1  \n","0                  1.0  \n","1                  1.0  \n","2                  1.0  \n","3                  1.0  \n","4                  1.0  \n","...                ...  \n","1681               0.0  \n","1682               0.0  \n","1683               0.0  \n","1684               0.0  \n","1685               0.0  \n","\n","[1686 rows x 44 columns]"],"text/html":["\n","  <div id=\"df-f18fa82f-c248-4cc4-a2f9-09b6184b36a0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>numTrials</th>\n","      <th>hour</th>\n","      <th>dayofweek</th>\n","      <th>uid_user_0</th>\n","      <th>uid_user_1</th>\n","      <th>uid_user_10</th>\n","      <th>uid_user_11</th>\n","      <th>uid_user_12</th>\n","      <th>uid_user_13</th>\n","      <th>uid_user_14</th>\n","      <th>...</th>\n","      <th>labname_lab02</th>\n","      <th>labname_lab03</th>\n","      <th>labname_lab03s</th>\n","      <th>labname_lab05s</th>\n","      <th>labname_laba04</th>\n","      <th>labname_laba04s</th>\n","      <th>labname_laba05</th>\n","      <th>labname_laba06</th>\n","      <th>labname_laba06s</th>\n","      <th>labname_project1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1681</th>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1682</th>\n","      <td>6</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1683</th>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1684</th>\n","      <td>8</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1685</th>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1686 rows × 44 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f18fa82f-c248-4cc4-a2f9-09b6184b36a0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f18fa82f-c248-4cc4-a2f9-09b6184b36a0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f18fa82f-c248-4cc4-a2f9-09b6184b36a0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["df = pd.read_csv('/content/drive/MyDrive/Школа 21/DS_project 14 Продвинутое машинное обучение/Task 4: Ансамбли/day-of-week-not-scaled.csv')\n","df"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"a-zPWMx_V15e","executionInfo":{"status":"ok","timestamp":1668097458704,"user_tz":-180,"elapsed":966,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"b462e3d5-cfea-470a-c16c-699c38df8695"}},{"cell_type":"code","execution_count":4,"outputs":[],"source":["X = df.drop(columns='dayofweek')\n","y = df['dayofweek']"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"4UML5U4GV15h","executionInfo":{"status":"ok","timestamp":1668097470854,"user_tz":-180,"elapsed":332,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}}}},{"cell_type":"code","execution_count":8,"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"xtEAKPTaV15k","executionInfo":{"status":"ok","timestamp":1668097677947,"user_tz":-180,"elapsed":364,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}}}},{"cell_type":"code","source":["y_train.value_counts(normalize=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4r9FtEiXkVl","executionInfo":{"status":"ok","timestamp":1668097679846,"user_tz":-180,"elapsed":11,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"44b8c11a-3b91-490c-d5e4-c60ae84a92ab"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3    0.234421\n","6    0.211424\n","1    0.162463\n","5    0.160979\n","2    0.088279\n","0    0.080861\n","4    0.061573\n","Name: dayofweek, dtype: float64"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["y_test.value_counts(normalize=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjOaEh2nXm19","executionInfo":{"status":"ok","timestamp":1668097682085,"user_tz":-180,"elapsed":489,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"8ce247f7-8666-4ae7-f3b8-e45d65ef117d"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3    0.236686\n","6    0.210059\n","1    0.162722\n","5    0.159763\n","2    0.088757\n","0    0.079882\n","4    0.062130\n","Name: dayofweek, dtype: float64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":11,"outputs":[],"source":["X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=21, stratify=y_train)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"qb38n-ZTV153","executionInfo":{"status":"ok","timestamp":1668097691254,"user_tz":-180,"elapsed":430,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}}}},{"cell_type":"code","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3    0.234694\n","6    0.211503\n","1    0.162338\n","5    0.161410\n","2    0.088126\n","0    0.080705\n","4    0.061224\n","Name: dayofweek, dtype: float64"]},"metadata":{},"execution_count":12}],"source":["y_train.value_counts(normalize=True)"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"f6eIcgzsV155","executionInfo":{"status":"ok","timestamp":1668097693402,"user_tz":-180,"elapsed":40,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"5249f0a1-9373-4454-d814-6f47dfb06ea4"}},{"cell_type":"code","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3    0.233333\n","6    0.211111\n","1    0.162963\n","5    0.159259\n","2    0.088889\n","0    0.081481\n","4    0.062963\n","Name: dayofweek, dtype: float64"]},"metadata":{},"execution_count":13}],"source":["y_valid.value_counts(normalize=True)"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"eSGwFg7JV159","executionInfo":{"status":"ok","timestamp":1668097695542,"user_tz":-180,"elapsed":10,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"61ec0b8a-83d1-48e9-a9d1-6ec1f712fe8c"}},{"cell_type":"markdown","metadata":{"id":"0MqRj_rHV15_"},"source":["## 2. Индивидуальные классификаторы"]},{"cell_type":"markdown","metadata":{"id":"WheViXn6V16A"},"source":["1. Обучите SVM, дерево классификации и случайный лес опять же с наилучшими параметрами, которые вы обнаружили в task 02. Используйте параметр `random_state=21` для всех из них.\n","2. Оцените `accuracy`, `precision` и `recall` для всех из них на валидационном куске данных.\n","3. Формат результата каждой ячейки должен выглядеть так:\n","\n","```\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","```"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8pTZjZtV16D","executionInfo":{"status":"ok","timestamp":1668098138043,"user_tz":-180,"elapsed":623,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"844b83c5-1db6-43a0-ec78-17a4204d6c2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n"]}],"source":["svc = SVC(C=10, class_weight=None, gamma='auto', kernel='rbf', random_state=21, probability=True)\n","svc.fit(X_train, y_train)\n","y_pred = svc.predict(X_valid)\n","print(f'accuracy is {accuracy_score(y_valid, y_pred):.5f}\\nprecision is {precision_score(y_valid, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_valid, y_pred, average=\"weighted\"):.5f}')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrtvGFP1V16E","executionInfo":{"status":"ok","timestamp":1668098159460,"user_tz":-180,"elapsed":21,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"fd0f947d-370c-49f7-f5f2-21e344f78af3"},"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n"]}],"source":["dt = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=21, random_state=21)\n","dt.fit(X_train, y_train)\n","y_pred = dt.predict(X_valid)\n","print(f'accuracy is {accuracy_score(y_valid, y_pred):.5f}\\nprecision is {precision_score(y_valid, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_valid, y_pred, average=\"weighted\"):.5f}')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QfAfrMJV16G","executionInfo":{"status":"ok","timestamp":1668098185301,"user_tz":-180,"elapsed":388,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"53e8a677-e70d-4a60-d4c3-33084efa0460"},"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy is 0.88519\n","precision is 0.88562\n","recall is 0.88519\n"]}],"source":["rf = RandomForestClassifier(class_weight='balanced', criterion='entropy', max_depth=24, n_estimators=100, random_state=21)\n","rf.fit(X_train, y_train)\n","y_pred = rf.predict(X_valid)\n","print(f'accuracy is {accuracy_score(y_valid, y_pred):.5f}\\nprecision is {precision_score(y_valid, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_valid, y_pred, average=\"weighted\"):.5f}')"]},{"cell_type":"markdown","metadata":{"id":"aahYbjtkV16J"},"source":["## 3. Voting classifiers"]},{"cell_type":"markdown","metadata":{"id":"jn4h6dLoV16K"},"source":["1. Объедините три модели, которые вы только что обучили, в один `VotingClassifier`. Посчитайте `accuracy`, `precision`, `recall` на валидационной выборке.\n","2. Поиграйте с разными параметрами `VotingClassifier`.\n","3. Посчитайте `accuracy`, `precision` и `recall` для тестовой выборки для того `VotingClassifier`, у которого наилучшие веса с точки зрения `accuracy` на валидационной выборке (если несколько моделей имеют одинаковое `accuracy`, то выберите ту, у которой более высокий `precision`)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iu_h7wa_V16L","outputId":"00811704-3abf-4548-88fa-b18c2ca49242"},"outputs":[{"name":"stdout","output_type":"stream","text":["voting is hard, weights is [1, 1, 1]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [1, 1, 2]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 1, 3]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 1, 4]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 1, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 2, 1]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [1, 2, 2]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [1, 2, 3]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 2, 4]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 2, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 3, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [1, 3, 2]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [1, 3, 3]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [1, 3, 4]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 3, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 4, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [1, 4, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [1, 4, 3]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [1, 4, 4]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [1, 4, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [1, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [1, 5, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [1, 5, 3]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [1, 5, 4]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [1, 5, 5]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [2, 1, 1]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [2, 1, 2]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [2, 1, 3]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 1, 4]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 1, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 2, 1]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [2, 2, 2]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [2, 2, 3]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 2, 4]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 2, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 3, 1]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [2, 3, 2]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [2, 3, 3]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [2, 3, 4]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 3, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 4, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [2, 4, 2]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [2, 4, 3]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [2, 4, 4]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [2, 4, 5]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [2, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [2, 5, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [2, 5, 3]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [2, 5, 4]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [2, 5, 5]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [3, 1, 1]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [3, 1, 2]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [3, 1, 3]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [3, 1, 4]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 1, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 2, 1]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [3, 2, 2]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [3, 2, 3]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [3, 2, 4]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 2, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 3, 1]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [3, 3, 2]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [3, 3, 3]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [3, 3, 4]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 3, 5]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 4, 1]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [3, 4, 2]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [3, 4, 3]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [3, 4, 4]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [3, 4, 5]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [3, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is hard, weights is [3, 5, 2]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [3, 5, 3]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [3, 5, 4]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [3, 5, 5]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [4, 1, 1]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [4, 1, 2]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [4, 1, 3]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [4, 1, 4]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 1, 5]\n","accuracy is 0.89630\n","precision is 0.89698\n","recall is 0.89630\n","\n","voting is hard, weights is [4, 2, 1]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [4, 2, 2]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [4, 2, 3]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 2, 4]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 2, 5]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [4, 3, 1]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [4, 3, 2]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 3, 3]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 3, 4]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 3, 5]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [4, 4, 1]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [4, 4, 2]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [4, 4, 3]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [4, 4, 4]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [4, 4, 5]\n","accuracy is 0.89630\n","precision is 0.89675\n","recall is 0.89630\n","\n","voting is hard, weights is [4, 5, 1]\n","accuracy is 0.88889\n","precision is 0.89027\n","recall is 0.88889\n","\n","voting is hard, weights is [4, 5, 2]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [4, 5, 3]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [4, 5, 4]\n","accuracy is 0.90741\n","precision is 0.90773\n","recall is 0.90741\n","\n","voting is hard, weights is [4, 5, 5]\n","accuracy is 0.90370\n","precision is 0.90360\n","recall is 0.90370\n","\n","voting is hard, weights is [5, 1, 1]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [5, 1, 2]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [5, 1, 3]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [5, 1, 4]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [5, 1, 5]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 2, 1]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [5, 2, 2]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [5, 2, 3]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [5, 2, 4]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 2, 5]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 3, 1]\n","accuracy is 0.87778\n","precision is 0.88162\n","recall is 0.87778\n","\n","voting is hard, weights is [5, 3, 2]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [5, 3, 3]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 3, 4]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 3, 5]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 4, 1]\n","accuracy is 0.88519\n","precision is 0.88979\n","recall is 0.88519\n","\n","voting is hard, weights is [5, 4, 2]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 4, 3]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 4, 4]\n","accuracy is 0.90000\n","precision is 0.89994\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 4, 5]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is hard, weights is [5, 5, 1]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [5, 5, 2]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [5, 5, 3]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [5, 5, 4]\n","accuracy is 0.90370\n","precision is 0.90358\n","recall is 0.90370\n","\n","voting is hard, weights is [5, 5, 5]\n","accuracy is 0.90000\n","precision is 0.89993\n","recall is 0.90000\n","\n","voting is soft, weights is [1, 1, 1]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [1, 1, 2]\n","accuracy is 0.90000\n","precision is 0.90180\n","recall is 0.90000\n","\n","voting is soft, weights is [1, 1, 3]\n","accuracy is 0.89630\n","precision is 0.89780\n","recall is 0.89630\n","\n","voting is soft, weights is [1, 1, 4]\n","accuracy is 0.90000\n","precision is 0.90023\n","recall is 0.90000\n","\n","voting is soft, weights is [1, 1, 5]\n","accuracy is 0.90000\n","precision is 0.90023\n","recall is 0.90000\n","\n","voting is soft, weights is [1, 2, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 2, 2]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [1, 2, 3]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [1, 2, 4]\n","accuracy is 0.88148\n","precision is 0.88414\n","recall is 0.88148\n","\n","voting is soft, weights is [1, 2, 5]\n","accuracy is 0.88519\n","precision is 0.88803\n","recall is 0.88519\n","\n","voting is soft, weights is [1, 3, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 3, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 3, 3]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [1, 3, 4]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [1, 3, 5]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [1, 4, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 4, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 4, 3]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 4, 4]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [1, 4, 5]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [1, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 5, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 5, 3]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 5, 4]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [1, 5, 5]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 1, 1]\n","accuracy is 0.90000\n","precision is 0.90072\n","recall is 0.90000\n","\n","voting is soft, weights is [2, 1, 2]\n","accuracy is 0.90370\n","precision is 0.90462\n","recall is 0.90370\n","\n","voting is soft, weights is [2, 1, 3]\n","accuracy is 0.90000\n","precision is 0.89985\n","recall is 0.90000\n","\n","voting is soft, weights is [2, 1, 4]\n","accuracy is 0.90370\n","precision is 0.90436\n","recall is 0.90370\n","\n","voting is soft, weights is [2, 1, 5]\n","accuracy is 0.90370\n","precision is 0.90436\n","recall is 0.90370\n","\n","voting is soft, weights is [2, 2, 1]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [2, 2, 2]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [2, 2, 3]\n","accuracy is 0.89630\n","precision is 0.89878\n","recall is 0.89630\n","\n","voting is soft, weights is [2, 2, 4]\n","accuracy is 0.90000\n","precision is 0.90180\n","recall is 0.90000\n","\n","voting is soft, weights is [2, 2, 5]\n","accuracy is 0.90000\n","precision is 0.90180\n","recall is 0.90000\n","\n","voting is soft, weights is [2, 3, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 3, 2]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [2, 3, 3]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [2, 3, 4]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [2, 3, 5]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [2, 4, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 4, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 4, 3]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 4, 4]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [2, 4, 5]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [2, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 5, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 5, 3]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 5, 4]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [2, 5, 5]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [3, 1, 1]\n","accuracy is 0.90370\n","precision is 0.90607\n","recall is 0.90370\n","\n","voting is soft, weights is [3, 1, 2]\n","accuracy is 0.90370\n","precision is 0.90397\n","recall is 0.90370\n","\n","voting is soft, weights is [3, 1, 3]\n","accuracy is 0.90370\n","precision is 0.90364\n","recall is 0.90370\n","\n","voting is soft, weights is [3, 1, 4]\n","accuracy is 0.90000\n","precision is 0.89985\n","recall is 0.90000\n","\n","voting is soft, weights is [3, 1, 5]\n","accuracy is 0.90000\n","precision is 0.89997\n","recall is 0.90000\n","\n","voting is soft, weights is [3, 2, 1]\n","accuracy is 0.90000\n","precision is 0.90240\n","recall is 0.90000\n","\n","voting is soft, weights is [3, 2, 2]\n","accuracy is 0.90370\n","precision is 0.90610\n","recall is 0.90370\n","\n","voting is soft, weights is [3, 2, 3]\n","accuracy is 0.90370\n","precision is 0.90610\n","recall is 0.90370\n","\n","voting is soft, weights is [3, 2, 4]\n","accuracy is 0.90741\n","precision is 0.91012\n","recall is 0.90741\n","\n","voting is soft, weights is [3, 2, 5]\n","accuracy is 0.90000\n","precision is 0.90180\n","recall is 0.90000\n","\n","voting is soft, weights is [3, 3, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [3, 3, 2]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [3, 3, 3]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [3, 3, 4]\n","accuracy is 0.88519\n","precision is 0.88816\n","recall is 0.88519\n","\n","voting is soft, weights is [3, 3, 5]\n","accuracy is 0.90000\n","precision is 0.90248\n","recall is 0.90000\n","\n","voting is soft, weights is [3, 4, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [3, 4, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [3, 4, 3]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [3, 4, 4]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [3, 4, 5]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [3, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [3, 5, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [3, 5, 3]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [3, 5, 4]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [3, 5, 5]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [4, 1, 1]\n","accuracy is 0.90741\n","precision is 0.91026\n","recall is 0.90741\n","\n","voting is soft, weights is [4, 1, 2]\n","accuracy is 0.90741\n","precision is 0.91026\n","recall is 0.90741\n","\n","voting is soft, weights is [4, 1, 3]\n","accuracy is 0.90741\n","precision is 0.91099\n","recall is 0.90741\n","\n","voting is soft, weights is [4, 1, 4]\n","accuracy is 0.91111\n","precision is 0.91288\n","recall is 0.91111\n","\n","voting is soft, weights is [4, 1, 5]\n","accuracy is 0.91111\n","precision is 0.91144\n","recall is 0.91111\n","\n","voting is soft, weights is [4, 2, 1]\n","accuracy is 0.90000\n","precision is 0.90122\n","recall is 0.90000\n","\n","voting is soft, weights is [4, 2, 2]\n","accuracy is 0.90000\n","precision is 0.90072\n","recall is 0.90000\n","\n","voting is soft, weights is [4, 2, 3]\n","accuracy is 0.90370\n","precision is 0.90514\n","recall is 0.90370\n","\n","voting is soft, weights is [4, 2, 4]\n","accuracy is 0.90370\n","precision is 0.90462\n","recall is 0.90370\n","\n","voting is soft, weights is [4, 2, 5]\n","accuracy is 0.90000\n","precision is 0.89985\n","recall is 0.90000\n","\n","voting is soft, weights is [4, 3, 1]\n","accuracy is 0.87407\n","precision is 0.87821\n","recall is 0.87407\n","\n","voting is soft, weights is [4, 3, 2]\n","accuracy is 0.89259\n","precision is 0.89605\n","recall is 0.89259\n","\n","voting is soft, weights is [4, 3, 3]\n","accuracy is 0.90000\n","precision is 0.90281\n","recall is 0.90000\n","\n","voting is soft, weights is [4, 3, 4]\n","accuracy is 0.90370\n","precision is 0.90587\n","recall is 0.90370\n","\n","voting is soft, weights is [4, 3, 5]\n","accuracy is 0.90370\n","precision is 0.90587\n","recall is 0.90370\n","\n","voting is soft, weights is [4, 4, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [4, 4, 2]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [4, 4, 3]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [4, 4, 4]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","voting is soft, weights is [4, 4, 5]\n","accuracy is 0.88148\n","precision is 0.88472\n","recall is 0.88148\n","\n","voting is soft, weights is [4, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [4, 5, 2]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [4, 5, 3]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [4, 5, 4]\n","accuracy is 0.87407\n","precision is 0.87798\n","recall is 0.87407\n","\n","voting is soft, weights is [4, 5, 5]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [5, 1, 1]\n","accuracy is 0.90741\n","precision is 0.91149\n","recall is 0.90741\n","\n","voting is soft, weights is [5, 1, 2]\n","accuracy is 0.90741\n","precision is 0.91149\n","recall is 0.90741\n","\n","voting is soft, weights is [5, 1, 3]\n","accuracy is 0.90370\n","precision is 0.90855\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 1, 4]\n","accuracy is 0.90370\n","precision is 0.90782\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 1, 5]\n","accuracy is 0.90741\n","precision is 0.90956\n","recall is 0.90741\n","\n","voting is soft, weights is [5, 2, 1]\n","accuracy is 0.89630\n","precision is 0.89860\n","recall is 0.89630\n","\n","voting is soft, weights is [5, 2, 2]\n","accuracy is 0.90370\n","precision is 0.90439\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 2, 3]\n","accuracy is 0.90741\n","precision is 0.90761\n","recall is 0.90741\n","\n","voting is soft, weights is [5, 2, 4]\n","accuracy is 0.90741\n","precision is 0.90761\n","recall is 0.90741\n","\n","voting is soft, weights is [5, 2, 5]\n","accuracy is 0.90370\n","precision is 0.90364\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 3, 1]\n","accuracy is 0.89630\n","precision is 0.89836\n","recall is 0.89630\n","\n","voting is soft, weights is [5, 3, 2]\n","accuracy is 0.90370\n","precision is 0.90610\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 3, 3]\n","accuracy is 0.90741\n","precision is 0.90970\n","recall is 0.90741\n","\n","voting is soft, weights is [5, 3, 4]\n","accuracy is 0.90370\n","precision is 0.90610\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 3, 5]\n","accuracy is 0.90370\n","precision is 0.90610\n","recall is 0.90370\n","\n","voting is soft, weights is [5, 4, 1]\n","accuracy is 0.87407\n","precision is 0.87821\n","recall is 0.87407\n","\n","voting is soft, weights is [5, 4, 2]\n","accuracy is 0.87037\n","precision is 0.87351\n","recall is 0.87037\n","\n","voting is soft, weights is [5, 4, 3]\n","accuracy is 0.88148\n","precision is 0.88366\n","recall is 0.88148\n","\n","voting is soft, weights is [5, 4, 4]\n","accuracy is 0.89630\n","precision is 0.89878\n","recall is 0.89630\n","\n","voting is soft, weights is [5, 4, 5]\n","accuracy is 0.90000\n","precision is 0.90248\n","recall is 0.90000\n","\n","voting is soft, weights is [5, 5, 1]\n","accuracy is 0.86667\n","precision is 0.87170\n","recall is 0.86667\n","\n","voting is soft, weights is [5, 5, 2]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [5, 5, 3]\n","accuracy is 0.87037\n","precision is 0.87480\n","recall is 0.87037\n","\n","voting is soft, weights is [5, 5, 4]\n","accuracy is 0.87778\n","precision is 0.88161\n","recall is 0.87778\n","\n","voting is soft, weights is [5, 5, 5]\n","accuracy is 0.88519\n","precision is 0.88840\n","recall is 0.88519\n","\n","Best params: {'voting': 'soft', 'weights': [4, 1, 4]}, accuracy is 0.9111111111111111, precision is 0.9128814421216392, recall is 0.9111111111111111\n"]}],"source":["best_accuracy = 0\n","best_precision = 0\n","best_recall = 0\n","best_params = 0\n","for voting in ['hard', 'soft']:\n","    for weight_1 in range(1, 6):\n","        for weight_2 in range(1, 6):\n","            for weight_3 in range(1, 6):\n","                vc = VotingClassifier(estimators=[('SVC', svc), ('DecisionTreeClassifier', dt), ('RandomForestClassifier', rf)], voting=voting, weights=[weight_1, weight_2, weight_3])\n","                vc.fit(X_train, y_train)\n","                y_pred = vc.predict(X_valid)\n","                print(f'voting is {voting}, weights is {[weight_1, weight_2, weight_3]}')\n","                print(f'accuracy is {accuracy_score(y_valid, y_pred):.5f}\\nprecision is {precision_score(y_valid, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_valid, y_pred, average=\"weighted\"):.5f}')\n","                print()\n","                if (accuracy_score(y_valid, y_pred) > best_accuracy) or (accuracy_score(y_valid, y_pred) == best_accuracy and best_precision < precision_score(y_valid, y_pred, average=\"weighted\")):\n","                    best_accuracy = accuracy_score(y_valid, y_pred)\n","                    best_precision = precision_score(y_valid, y_pred, average=\"weighted\")\n","                    best_recall = recall_score(y_valid, y_pred, average=\"weighted\")\n","                    best_params = {'voting': voting, 'weights': [weight_1, weight_2, weight_3]}\n","\n","\n","print(f'Best params: {best_params}, accuracy is {best_accuracy}, precision is {best_precision}, recall is {best_recall}')"]},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy is 0.90533\n","precision is 0.90881\n","recall is 0.90533\n"]}],"source":["vc = VotingClassifier(estimators=[('SVC', svc), ('DecisionTreeClassifier', dt), ('RandomForestClassifier', rf)], voting='soft', weights=[4, 1, 4])\n","vc.fit(X_train, y_train)\n","y_pred = vc.predict(X_test)\n","print(f'accuracy is {accuracy_score(y_test, y_pred):.5f}\\nprecision is {precision_score(y_test, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_test, y_pred, average=\"weighted\"):.5f}')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"EP6dLd0fV16M","outputId":"080381ae-9279-41f3-ae69-5fab3036571a"}},{"cell_type":"markdown","metadata":{"id":"3HwhrT67V16N"},"source":["## 4. Bagging classifiers"]},{"cell_type":"markdown","metadata":{"id":"oKMZbYMtV16P"},"source":["1. Используйте `SVM` с наилучшими параметрами для создания ансамбля `BaggingClassifier`. Попробуйте различные значения `n_estimators`. Используйте `random_state=21`.\n","2. Поиграйте с разными параметрами `BaggingClassifier`.\n","3. Посчитайте `accuracy`, `precision` и `recall` для тестовой выборки для того `BaggingClassifier`, у которого наилучшие веса с точки зрения `accuracy` на валидационной выборке (если несколько моделей имеют одинаковое `accuracy`, то выберите ту, у которой более высокий `precision`)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9acWJF7KV16P","outputId":"e8eca68c-3861-41c3-802b-599d33652b7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["n_estimators is 1\n","accuracy is 0.84024\n","precision is 0.84592\n","recall is 0.84024\n","\n","n_estimators is 2\n","accuracy is 0.83432\n","precision is 0.83794\n","recall is 0.83432\n","\n","n_estimators is 3\n","accuracy is 0.84911\n","precision is 0.85597\n","recall is 0.84911\n","\n","n_estimators is 4\n","accuracy is 0.84911\n","precision is 0.85377\n","recall is 0.84911\n","\n","n_estimators is 5\n","accuracy is 0.84911\n","precision is 0.85798\n","recall is 0.84911\n","\n","n_estimators is 6\n","accuracy is 0.85207\n","precision is 0.85948\n","recall is 0.85207\n","\n","n_estimators is 7\n","accuracy is 0.86391\n","precision is 0.86900\n","recall is 0.86391\n","\n","n_estimators is 8\n","accuracy is 0.86095\n","precision is 0.86633\n","recall is 0.86095\n","\n","n_estimators is 9\n","accuracy is 0.86095\n","precision is 0.86625\n","recall is 0.86095\n","\n","n_estimators is 10\n","accuracy is 0.86391\n","precision is 0.86966\n","recall is 0.86391\n","\n","n_estimators is 11\n","accuracy is 0.85799\n","precision is 0.86421\n","recall is 0.85799\n","\n","n_estimators is 12\n","accuracy is 0.86982\n","precision is 0.87444\n","recall is 0.86982\n","\n","n_estimators is 13\n","accuracy is 0.86686\n","precision is 0.87348\n","recall is 0.86686\n","\n","n_estimators is 14\n","accuracy is 0.87870\n","precision is 0.88435\n","recall is 0.87870\n","\n","n_estimators is 15\n","accuracy is 0.86982\n","precision is 0.87536\n","recall is 0.86982\n","\n","n_estimators is 16\n","accuracy is 0.86982\n","precision is 0.87581\n","recall is 0.86982\n","\n","n_estimators is 17\n","accuracy is 0.86982\n","precision is 0.87591\n","recall is 0.86982\n","\n","n_estimators is 18\n","accuracy is 0.87278\n","precision is 0.87662\n","recall is 0.87278\n","\n","n_estimators is 19\n","accuracy is 0.87574\n","precision is 0.87955\n","recall is 0.87574\n","\n","n_estimators is 20\n","accuracy is 0.87278\n","precision is 0.87668\n","recall is 0.87278\n","\n","n_estimators is 21\n","accuracy is 0.86686\n","precision is 0.87089\n","recall is 0.86686\n","\n","n_estimators is 22\n","accuracy is 0.86686\n","precision is 0.87000\n","recall is 0.86686\n","\n","n_estimators is 23\n","accuracy is 0.86686\n","precision is 0.87188\n","recall is 0.86686\n","\n","n_estimators is 24\n","accuracy is 0.86982\n","precision is 0.87488\n","recall is 0.86982\n","\n","n_estimators is 25\n","accuracy is 0.87574\n","precision is 0.88031\n","recall is 0.87574\n","\n","n_estimators is 26\n","accuracy is 0.86686\n","precision is 0.87046\n","recall is 0.86686\n","\n","n_estimators is 27\n","accuracy is 0.86982\n","precision is 0.87335\n","recall is 0.86982\n","\n","n_estimators is 28\n","accuracy is 0.87278\n","precision is 0.87750\n","recall is 0.87278\n","\n","n_estimators is 29\n","accuracy is 0.86391\n","precision is 0.86937\n","recall is 0.86391\n","\n","n_estimators is 30\n","accuracy is 0.87278\n","precision is 0.87840\n","recall is 0.87278\n","\n","n_estimators is 31\n","accuracy is 0.87870\n","precision is 0.88400\n","recall is 0.87870\n","\n","n_estimators is 32\n","accuracy is 0.87278\n","precision is 0.87840\n","recall is 0.87278\n","\n","n_estimators is 33\n","accuracy is 0.86982\n","precision is 0.87537\n","recall is 0.86982\n","\n","n_estimators is 34\n","accuracy is 0.87278\n","precision is 0.87779\n","recall is 0.87278\n","\n","n_estimators is 35\n","accuracy is 0.86982\n","precision is 0.87589\n","recall is 0.86982\n","\n","n_estimators is 36\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 37\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 38\n","accuracy is 0.87574\n","precision is 0.88116\n","recall is 0.87574\n","\n","n_estimators is 39\n","accuracy is 0.87574\n","precision is 0.88116\n","recall is 0.87574\n","\n","n_estimators is 40\n","accuracy is 0.87574\n","precision is 0.88116\n","recall is 0.87574\n","\n","n_estimators is 41\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 42\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 43\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 44\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 45\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 46\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 47\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 48\n","accuracy is 0.88166\n","precision is 0.88632\n","recall is 0.88166\n","\n","n_estimators is 49\n","accuracy is 0.88166\n","precision is 0.88632\n","recall is 0.88166\n","\n","n_estimators is 50\n","accuracy is 0.88462\n","precision is 0.88941\n","recall is 0.88462\n","\n","n_estimators is 51\n","accuracy is 0.88166\n","precision is 0.88632\n","recall is 0.88166\n","\n","n_estimators is 52\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 53\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 54\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 55\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 56\n","accuracy is 0.87870\n","precision is 0.88360\n","recall is 0.87870\n","\n","n_estimators is 57\n","accuracy is 0.87574\n","precision is 0.88116\n","recall is 0.87574\n","\n","n_estimators is 58\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 59\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 60\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 61\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 62\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 63\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 64\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 65\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 66\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 67\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 68\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 69\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 70\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 71\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 72\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 73\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 74\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 75\n","accuracy is 0.88166\n","precision is 0.88672\n","recall is 0.88166\n","\n","n_estimators is 76\n","accuracy is 0.88166\n","precision is 0.88672\n","recall is 0.88166\n","\n","n_estimators is 77\n","accuracy is 0.87870\n","precision is 0.88395\n","recall is 0.87870\n","\n","n_estimators is 78\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 79\n","accuracy is 0.87870\n","precision is 0.88395\n","recall is 0.87870\n","\n","n_estimators is 80\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 81\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 82\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 83\n","accuracy is 0.88166\n","precision is 0.88674\n","recall is 0.88166\n","\n","n_estimators is 84\n","accuracy is 0.87870\n","precision is 0.88429\n","recall is 0.87870\n","\n","n_estimators is 85\n","accuracy is 0.88462\n","precision is 0.88941\n","recall is 0.88462\n","\n","n_estimators is 86\n","accuracy is 0.88166\n","precision is 0.88697\n","recall is 0.88166\n","\n","n_estimators is 87\n","accuracy is 0.88462\n","precision is 0.88941\n","recall is 0.88462\n","\n","n_estimators is 88\n","accuracy is 0.88462\n","precision is 0.88941\n","recall is 0.88462\n","\n","n_estimators is 89\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 90\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 91\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 92\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 93\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 94\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 95\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 96\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 97\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 98\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 99\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","n_estimators is 100\n","accuracy is 0.88462\n","precision is 0.88917\n","recall is 0.88462\n","\n","Best n_estimators: 50, accuracy is 0.8846153846153846, precision is 0.8894129703464362, recall is 0.8846153846153846\n"]}],"source":["best_accuracy = 0\n","best_precision = 0\n","best_recall = 0\n","best_n_estimators = 0\n","for n_estimators in range(1, 101):\n","    bc = BaggingClassifier(base_estimator=svc, n_estimators=n_estimators, random_state=21, n_jobs=-1)\n","    bc.fit(X_train, y_train)\n","    y_pred = bc.predict(X_test)\n","    print(f'n_estimators is {n_estimators}')\n","    print(f'accuracy is {accuracy_score(y_test, y_pred):.5f}\\nprecision is {precision_score(y_test, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_test, y_pred, average=\"weighted\"):.5f}')\n","    print()\n","    if (accuracy_score(y_test, y_pred) > best_accuracy) or (accuracy_score(y_test, y_pred) == best_accuracy and best_precision < precision_score(y_test, y_pred, average=\"weighted\")):\n","                    best_accuracy = accuracy_score(y_test, y_pred)\n","                    best_precision = precision_score(y_test, y_pred, average=\"weighted\")\n","                    best_recall = recall_score(y_test, y_pred, average=\"weighted\")\n","                    best_n_estimators =n_estimators\n","\n","print(f'Best n_estimators: {best_n_estimators}, accuracy is {best_accuracy}, precision is {best_precision}, recall is {best_recall}')"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"lcTFp2p6V16R","outputId":"45a57666-d7d2-4979-a261-ec0b2937ca0d"},"source":["print('n_estimators =', 50)\n","bc = BaggingClassifier(base_estimator=svc, n_estimators=50, random_state=21)\n","bc.fit(X_train, y_train)\n","y_pred = bc.predict(X_test)\n","print(f'accuracy is {accuracy_score(y_test, y_pred):.5f}\\nprecision is {precision_score(y_test, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_test, y_pred, average=\"weighted\"):.5f}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["n_estimators = 50\n","accuracy is 0.88462\n","precision is 0.88941\n","recall is 0.88462\n"]}]},{"cell_type":"markdown","metadata":{"id":"RYK3zjD1V16S"},"source":["## 5. Stacking classifiers"]},{"cell_type":"markdown","metadata":{"id":"MHbEieGPV16T"},"source":["1. Чтобы в этой подзадаче мы могли сохранить воспроизводимость результатов, вам потребуется вначале создать объект генератора кросс-валидации `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, где значение `n` вам нужно будет оптимизировать. Подробности ниже.\n","2. Объедините три модели, которые вы обучили ранее, в один StackingClassifier. Посчитайте accuracy, precision, recall на валидационной выборке. Попробуйте разные значения `n_splits` `[2, 3, 4, 5, 6, 7]` в генераторе кроссвалидации и разные значения параметра `passthrough` в самом StackingClassifier.\n","3. Посчитайте `accuracy`, `precision` и `recall` для тестовой выборки для того `StackingClassifier`, у которого наилучшие веса с точки зрения `accuracy` на валидационной выборке (если несколько моделей имеют одинаковое `accuracy`, то выберите ту, у которой более высокий `precision`). Используйте `final_estimator=LogisticRegression(solver='liblinear')`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsh8DQ_tV16U","outputId":"9b64aac9-fffc-4365-eb4d-844d67d920fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["n_splits is 2, passthrough is True\n","accuracy is 0.90370\n","precision is 0.90619\n","recall is 0.90370\n","\n","n_splits is 2, passthrough is False\n","accuracy is 0.89630\n","precision is 0.89678\n","recall is 0.89630\n","\n","n_splits is 3, passthrough is True\n","accuracy is 0.90370\n","precision is 0.90632\n","recall is 0.90370\n","\n","n_splits is 3, passthrough is False\n","accuracy is 0.89630\n","precision is 0.89759\n","recall is 0.89630\n","\n","n_splits is 4, passthrough is True\n","accuracy is 0.91111\n","precision is 0.91327\n","recall is 0.91111\n","\n","n_splits is 4, passthrough is False\n","accuracy is 0.90370\n","precision is 0.90570\n","recall is 0.90370\n","\n","n_splits is 5, passthrough is True\n","accuracy is 0.90000\n","precision is 0.90217\n","recall is 0.90000\n","\n","n_splits is 5, passthrough is False\n","accuracy is 0.90000\n","precision is 0.90056\n","recall is 0.90000\n","\n","n_splits is 6, passthrough is True\n","accuracy is 0.90370\n","precision is 0.90450\n","recall is 0.90370\n","\n","n_splits is 6, passthrough is False\n","accuracy is 0.90370\n","precision is 0.90436\n","recall is 0.90370\n","\n","n_splits is 7, passthrough is True\n","accuracy is 0.90370\n","precision is 0.90640\n","recall is 0.90370\n","\n","n_splits is 7, passthrough is False\n","accuracy is 0.90370\n","precision is 0.90538\n","recall is 0.90370\n","\n","Best params: {'n_splits': 4, 'passthrough': True}, accuracy is 0.9111111111111111, precision is 0.9132693602693602, recall is 0.9111111111111111\n"]}],"source":["best_accuracy = 0\n","best_precision = 0\n","best_recall = 0\n","best_params = 0\n","for n_splits in [2, 3, 4, 5, 6, 7]:\n","    for passthrough in [True, False]:\n","        sc = StackingClassifier(estimators=[('SVC', svc), ('DecisionTreeClassifier', dt), ('RandomForestClassifier', rf)], final_estimator=LogisticRegression(solver='liblinear'), cv=StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21), passthrough=passthrough, n_jobs=-1)\n","        sc.fit(X_train, y_train)\n","        y_pred = sc.predict(X_valid)\n","        print(f'n_splits is {n_splits}, passthrough is {passthrough}')\n","        print(f'accuracy is {accuracy_score(y_valid, y_pred):.5f}\\nprecision is {precision_score(y_valid, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_valid, y_pred, average=\"weighted\"):.5f}')\n","        print()\n","        if (accuracy_score(y_valid, y_pred) > best_accuracy) or (accuracy_score(y_valid, y_pred) == best_accuracy and best_precision < precision_score(y_valid, y_pred, average=\"weighted\")):\n","            best_accuracy = accuracy_score(y_valid, y_pred)\n","            best_precision = precision_score(y_valid, y_pred, average=\"weighted\")\n","            best_recall = recall_score(y_valid, y_pred, average=\"weighted\")\n","            best_params = {'n_splits': n_splits, 'passthrough': passthrough}\n","\n","print(f'Best params: {best_params}, accuracy is {best_accuracy}, precision is {best_precision}, recall is {best_recall}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rgFFVJJV16V","outputId":"07dcd784-6dc8-4fe2-b1cc-e14e6476c7f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy is 0.90533\n","precision is 0.90844\n","recall is 0.90533\n"]}],"source":["sc = StackingClassifier(estimators=[('SVC', svc), ('DecisionTreeClassifier', dt), ('RandomForestClassifier', rf)], final_estimator=LogisticRegression(solver='liblinear'), cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=21), passthrough=True, n_jobs=-1)\n","sc.fit(X_train, y_train)\n","y_pred = sc.predict(X_test)\n","print(f'accuracy is {accuracy_score(y_test, y_pred):.5f}\\nprecision is {precision_score(y_test, y_pred, average=\"weighted\"):.5f}\\nrecall is {recall_score(y_test, y_pred, average=\"weighted\"):.5f}')"]},{"cell_type":"markdown","metadata":{"id":"M8QX3lcEV16W"},"source":["## 6. Прогнозы"]},{"cell_type":"markdown","metadata":{"id":"fFjDe2_7V16X"},"source":["1. Выберите лучшую модель с точки зрения accuracy (если несколько моделей имеют одинаковое accuracy, то выберите ту, у которой более высокий precision).\n","2. Проанализируйте: для какого дня недели модель делает больше всего ошибок (в % от общего количество наблюдений этого класса в вашем датасете). Также проанализируйте на какой лаборатороной работе и на каком юзере модель делает больше всего ошибок.\n","3. Сохраните модель."]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"9jn3vGn7V16Y"},"source":["**Лучшая модель - VotingClassifier**"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUQVXau6V16Y","executionInfo":{"status":"ok","timestamp":1668098194021,"user_tz":-180,"elapsed":747,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"5e18e751-65be-4b18-c056-33e2c7acbf20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["VotingClassifier(estimators=[('SVC',\n","                              SVC(C=10, gamma='auto', probability=True,\n","                                  random_state=21)),\n","                             ('DecisionTreeClassifier',\n","                              DecisionTreeClassifier(class_weight='balanced',\n","                                                     max_depth=21,\n","                                                     random_state=21)),\n","                             ('RandomForestClassifier',\n","                              RandomForestClassifier(class_weight='balanced',\n","                                                     criterion='entropy',\n","                                                     max_depth=24,\n","                                                     random_state=21))],\n","                 voting='soft', weights=[4, 1, 4])"]},"metadata":{},"execution_count":18}],"source":["vc = VotingClassifier(estimators=[('SVC', svc), ('DecisionTreeClassifier', dt), ('RandomForestClassifier', rf)], voting='soft', weights=[4, 1, 4])\n","vc.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdMtOcaiV16a","executionInfo":{"status":"ok","timestamp":1668098215404,"user_tz":-180,"elapsed":844,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"726e5390-e7bb-4b10-a352-37e1b63d6779"},"outputs":[{"output_type":"stream","name":"stdout","text":["day: 0, mistakes: 25.93%\n","day: 1, mistakes: 7.27%\n","day: 2, mistakes: 6.67%\n","day: 3, mistakes: 3.75%\n","day: 4, mistakes: 9.52%\n","day: 5, mistakes: 12.96%\n","day: 6, mistakes: 8.45%\n"]}],"source":["for day in range(7):\n","    print(f'day: {day}, mistakes: {sum((y_test != vc.predict(X_test)) & (y_test == day)) / sum(y_test == day)*100:.2f}%')"]},{"cell_type":"markdown","source":["**Больше всего классификатор ошибается для понедельника в 25,93%**"],"metadata":{"collapsed":false,"id":"OppaOx46V16b"}},{"cell_type":"code","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["user: uid_user_0, mistakes: not in test\n","user: uid_user_1, mistakes: 0.000%\n","user: uid_user_10, mistakes: 0.000%\n","user: uid_user_11, mistakes: not in test\n","user: uid_user_12, mistakes: 0.000%\n","user: uid_user_13, mistakes: 11.765%\n","user: uid_user_14, mistakes: 9.677%\n","user: uid_user_15, mistakes: 0.000%\n","user: uid_user_16, mistakes: 20.000%\n","user: uid_user_17, mistakes: 28.571%\n","user: uid_user_18, mistakes: 16.667%\n","user: uid_user_19, mistakes: 15.789%\n","user: uid_user_2, mistakes: 14.286%\n","user: uid_user_20, mistakes: 0.000%\n","user: uid_user_21, mistakes: 0.000%\n","user: uid_user_22, mistakes: 0.000%\n","user: uid_user_23, mistakes: 0.000%\n","user: uid_user_24, mistakes: 9.091%\n","user: uid_user_25, mistakes: 9.091%\n","user: uid_user_26, mistakes: 0.000%\n","user: uid_user_27, mistakes: 16.667%\n","user: uid_user_28, mistakes: 0.000%\n","user: uid_user_29, mistakes: 9.091%\n","user: uid_user_3, mistakes: 14.286%\n","user: uid_user_30, mistakes: 12.500%\n","user: uid_user_31, mistakes: 11.111%\n","user: uid_user_4, mistakes: 11.111%\n","user: uid_user_6, mistakes: 50.000%\n","user: uid_user_7, mistakes: not in test\n","user: uid_user_8, mistakes: 0.000%\n"]}],"source":["for column in X.columns:\n","    if 'user' in column:\n","        print(f'user: {column}, mistakes: ', end='')\n","        if len(X_test[X_test[column] == 1.0]) > 0:\n","            print(f'{1 - accuracy_score(y_test[X_test[column] == 1.0], vc.predict(X_test[X_test[column] == 1.0])):.3%}')\n","        else:\n","            print('not in test')"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"_nPZCoBMV16c","executionInfo":{"status":"ok","timestamp":1668098243499,"user_tz":-180,"elapsed":1013,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"8a1ca161-4b6e-4479-bddb-ec8d26bc132e"}},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"hTGcjD2GV16c"},"source":["**Классификатор чаще всего ошибается для uid_user_6 в 50% случаев,\n","uid_user_0, uid_user_11, uid_user_7 нет в тестовой выборке**"]},{"cell_type":"code","source":["for column in X.columns:\n","    if 'labname' in column:\n","        print(f'labname: {column}, mistakes: ', end='')\n","        if len(X_test[X_test[column] == 1.0]) > 0:\n","            print(f'{1 - accuracy_score(y_test[X_test[column] == 1.0], rf.predict(X_test[X_test[column] == 1.0])):.3%}')\n","        else:\n","            print('not in test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMUzurIpZ4cF","executionInfo":{"status":"ok","timestamp":1668098284014,"user_tz":-180,"elapsed":379,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}},"outputId":"cda3277f-3eea-4a64-c2b8-48bbcab5e113"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["labname: labname_code_rvw, mistakes: 7.692%\n","labname: labname_lab02, mistakes: not in test\n","labname: labname_lab03, mistakes: 100.000%\n","labname: labname_lab03s, mistakes: 100.000%\n","labname: labname_lab05s, mistakes: 16.667%\n","labname: labname_laba04, mistakes: 20.000%\n","labname: labname_laba04s, mistakes: 16.000%\n","labname: labname_laba05, mistakes: 2.128%\n","labname: labname_laba06, mistakes: 11.111%\n","labname: labname_laba06s, mistakes: 6.667%\n","labname: labname_project1, mistakes: 5.376%\n"]}]},{"cell_type":"markdown","source":["**Классификатор чаще всего ошибается для labname_lab03 в 100% случаев,\n","labname_lab02 нет в тестовой выборке**"],"metadata":{"id":"tRYk9P2sZ-Z_"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from joblib import dump, load"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"hmYssp6pV16d"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"['best.joblib']"},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["dump(vc, 'best.joblib')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"RVpqAOkOV16d","outputId":"ac287304-0645-41f7-dbe7-cd29f009f012"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["best1 = load('best.joblib')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"bCa7972RV16e"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"0.9053254437869822"},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(y_test, best1.predict(X_test))"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"cvyEoY-CV16o","outputId":"3edeb76e-e07a-4b7c-9079-553084d849f2"}}],"metadata":{"kernelspec":{"name":"pycharm-209b2b6f","language":"python","display_name":"PyCharm (school21)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}